{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6802a21c-1f23-4a15-bea2-77deb0d7cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from line import Line\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748aee77-b56f-4d63-8574-1b3925eb6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, alpha=0.8, beta=1., gamma=0.):\n",
    "    \"\"\"\n",
    "    initial_img * alpha + img * beta + gamma\n",
    "    \"\"\"\n",
    "    img = np.uint8(img)\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.dstack((img, np.zeros_like(img), np.zeros_like(img)))\n",
    "\n",
    "    return cv2.addWeighted(initial_img, alpha, img, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28c32f2-9ebb-401e-8f98-1d5a225d829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2] \n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return masked_image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca625e5-1f0e-4486-a872-63b0082b9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lane_from_candidate_lines(cand_lines,img_shape):\n",
    "    pos_lines=[line for line in cand_lines if line.slope > 0]\n",
    "    neg_lines=[line for line in cand_lines if line.slope < 0]\n",
    "\n",
    "    neg_bias=np.median([line.bias for line in neg_lines]).astype(int)\n",
    "    neg_slope=np.median([line.slope for line in neg_lines])\n",
    "    x1, y1 = 0, neg_bias\n",
    "    x2, y2 = -np.int32(np.round(neg_bias / neg_slope)), 0\n",
    "    left_lane = Line(x1, y1, x2, y2)\n",
    "\n",
    "    pos_bias=np.median([line.bias for line in pos_lines]).astype(int)\n",
    "    pos_slope=np.median([line.slope for line in pos_lines])\n",
    "    x1, y1 = 0, pos_bias\n",
    "    x2, y2 = np.int32(np.round((img_shape[0] - pos_bias) / pos_slope)), img_shape[0]\n",
    "    right_lane = Line(x1, y1, x2, y2)\n",
    "    return left_lane , right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5942dc54-24f5-40c7-a674-a5777ee3977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothen_over_time(lane_lines):\n",
    "    if not lane_lines:\n",
    "        return None\n",
    "\n",
    "    avg_line_left = np.zeros((len(lane_lines), 4))\n",
    "    avg_line_right = np.zeros((len(lane_lines), 4))\n",
    "\n",
    "    for t in range(0, len(lane_lines)):\n",
    "        if lane_lines[t]:\n",
    "            avg_line_left[t] += lane_lines[t][0].get_coords()\n",
    "            avg_line_right[t] += lane_lines[t][1].get_coords()\n",
    "\n",
    "    avg_line_left = np.nanmean(avg_line_left, axis=0)\n",
    "    avg_line_right = np.nanmean(avg_line_right, axis=0)\n",
    "\n",
    "    return Line(*avg_line_left), Line(*avg_line_right) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4b6809-eadb-4b1a-84bb-33eb11adc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_line(img,rho,theta,threshold,min_line_len,max_line_gap):\n",
    "    end_points=cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,maxLineGap=max_line_gap)\n",
    "    return end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9850d15c-92eb-4b0a-a716-d7bd9f73ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lanes(frame , solid_lines):\n",
    "    resized_image = cv2.resize(frame,(960, 540))\n",
    "    scaled_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    preprocessed_image = cv2.GaussianBlur(scaled_image,(17,17),0)\n",
    "    edge_image = cv2.Canny(preprocessed_image,threshold1=50, threshold2=80)\n",
    "    end_points = hough_line(img=edge_image, rho=2, theta=np.pi / 180, threshold=1, min_line_len=15, max_line_gap=5)\n",
    "\n",
    "    detected_lines = [Line(l[0][0], l[0][1], l[0][2], l[0][3]) for l in end_points]\n",
    "\n",
    "    if solid_lines:\n",
    "        candidate_lines=[]\n",
    "        for line in detected_lines:\n",
    "            if (0.5 <= np.abs(line.slope) <= 2):\n",
    "                candidate_lines.append(line)\n",
    "        left_and_right_lanes = compute_lane_from_candidate_lines(cand_lines = candidate_lines , img_shape=scaled_image.shape)\n",
    "    else:\n",
    "        left_and_right_lanes = detected_lines\n",
    "        \n",
    "    return left_and_right_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b59ffff-85b3-4a52-a979-cd75a7d9222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_detection_pipeline(frames ,solid_lines=True , temporal_smoothing=True):\n",
    "    is_video =len(frames)>0\n",
    "    img_h , img_w = frames[0].shape[0] , frames[0].shape[1]\n",
    "\n",
    "    lane_lines=[]\n",
    "    for t in range(len(frames)):\n",
    "        lanes_for_frame=get_lanes(frame=frames[t], solid_lines=solid_lines)\n",
    "        lane_lines.append(lanes_for_frame)\n",
    "\n",
    "    if solid_lines and temporal_smoothing:\n",
    "            lane_lines = smoothen_over_time(lane_lines=lane_lines)\n",
    "    else:\n",
    "            lane_lines = lane_lines[0]\n",
    "\n",
    "    if lane_lines:\n",
    "            print('Got a Line')\n",
    "        \n",
    "    line_img = np.zeros(shape=(img_h, img_w))\n",
    "\n",
    "    for lane in lane_lines:\n",
    "            lane.draw(line_img)\n",
    "\n",
    " \n",
    "    vertices = np.array([[(50, img_h),\n",
    "                              (450, 310),\n",
    "                              (490, 310),\n",
    "                             (img_w - 50, img_h)]],\n",
    "                             dtype=np.int32)\n",
    "    img_masked, _ = region_of_interest(img = line_img, vertices = vertices)\n",
    "\n",
    "    \n",
    "    img_color = frames[-1] if is_video else frames[0]\n",
    "    img_blend = weighted_img(img=img_masked, initial_img=img_color, alpha=0.8, beta=1., gamma=0.)\n",
    "\n",
    "    return img_blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5a924-aacf-403c-bf65-4d8787c5daef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68090b9a-bed8-434f-b00b-b850287faf90",
   "metadata": {},
   "source": [
    "# MAIN fUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "989fe2be-58c5-484e-a4a8-9e64ac9a26c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\solidWhiteCurve.jpg\n",
      "Got a Line\n",
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\solidWhiteRight.jpg\n",
      "Got a Line\n",
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\solidYellowCurve.jpg\n",
      "Got a Line\n",
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\solidYellowCurve2.jpg\n",
      "Got a Line\n",
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\solidYellowLeft.jpg\n",
      "Got a Line\n",
      "processing image D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images\\whiteCarLaneSwitch.jpg\n",
      "Got a Line\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    resize_h, resize_w = 540, 960\n",
    "    output_image=r'D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\ouput_images\\images'\n",
    "    output_vedio=r'D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\ouput_images\\vedios'\n",
    "\n",
    "    test_dir=r'D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_images'\n",
    "    test_video_dir=r'D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_videos'\n",
    "    test_images=[os.path.join(test_dir,image) for image in os.listdir(test_dir)]\n",
    "\n",
    "    for image in test_images:\n",
    "        print(f'processing image {image}')\n",
    "\n",
    "        out_path = os.path.join(output_image,os.path.basename(image))\n",
    "        in_image = cv2.cvtColor(cv2.imread(image, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "        out_image=line_detection_pipeline([in_image],solid_lines=True , temporal_smoothing=True)\n",
    "        cv2.imwrite(out_path, cv2.cvtColor(out_image, cv2.COLOR_RGB2BGR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5b2baa-c465-4e5d-be93-5a93ac84f3ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: D:\\slashmark internship\\reference\\intermediate\\self-driving-car-master\\project_1_lane_finding_basic\\data\\test_videos\\solidWhiteRight.mp4\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n",
      "Got a Line\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "test_videos = [os.path.join(test_video_dir, name) for name in os.listdir(test_video_dir)]\n",
    "\n",
    "for test_video in test_videos:\n",
    "\n",
    "        print('Processing video: {}'.format(test_video))\n",
    "\n",
    "        cap = cv2.VideoCapture(test_video)\n",
    "        out = cv2.VideoWriter(os.path.join(output_vedio, os.path.basename(test_video)),\n",
    "                              fourcc=cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "                              fps=20.0, frameSize=(resize_w, resize_h))\n",
    "\n",
    "        frame_buffer = deque(maxlen=10)\n",
    "        while cap.isOpened():\n",
    "                ret, color_frame = cap.read()\n",
    "                if ret:\n",
    "                         color_frame = cv2.cvtColor(color_frame, cv2.COLOR_BGR2RGB)\n",
    "                         color_frame = cv2.resize(color_frame, (resize_w, resize_h))\n",
    "                         frame_buffer.append(color_frame)\n",
    "                         blend_frame = line_detection_pipeline(frames=frame_buffer, solid_lines=True, temporal_smoothing=True)\n",
    "                         out.write(cv2.cvtColor(blend_frame, cv2.COLOR_RGB2BGR))\n",
    "                         cv2.imshow('blend', cv2.cvtColor(blend_frame, cv2.COLOR_RGB2BGR)), cv2.waitKey(1)\n",
    "                else:\n",
    "                         break\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471996e1-79bf-415e-934c-07539e28c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
